{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input X (word embeddings):\n",
      " [[1. 0. 1. 0.]\n",
      " [0. 2. 0. 2.]\n",
      " [1. 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x, axis=-1, keepdims=True))\n",
    "    return e_x / np.sum(e_x, axis=-1, keepdims=True)\n",
    "\n",
    "# Step 1: Input sentence embeddings (3 words, 4-dimensional each)\n",
    "X = np.array([\n",
    "    [1.0, 0.0, 1.0, 0.0],  # \"The\"\n",
    "    [0.0, 2.0, 0.0, 2.0],  # \"cat\"\n",
    "    [1.0, 1.0, 1.0, 1.0]   # \"sat\"\n",
    "])\n",
    "print(\"Input X (word embeddings):\\n\", X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Create Q, K, V matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Linear Transformation:\n",
      "\n",
      "Weight matrix W_q:\n",
      " [[0.5488135  0.71518937 0.60276338 0.54488318]\n",
      " [0.4236548  0.64589411 0.43758721 0.891773  ]\n",
      " [0.96366276 0.38344152 0.79172504 0.52889492]\n",
      " [0.56804456 0.92559664 0.07103606 0.0871293 ]]\n",
      "\n",
      "Weight matrix W_k:\n",
      " [[0.0202184  0.83261985 0.77815675 0.87001215]\n",
      " [0.97861834 0.79915856 0.46147936 0.78052918]\n",
      " [0.11827443 0.63992102 0.14335329 0.94466892]\n",
      " [0.52184832 0.41466194 0.26455561 0.77423369]]\n",
      "\n",
      "Weight matrix W_v:\n",
      " [[0.45615033 0.56843395 0.0187898  0.6176355 ]\n",
      " [0.61209572 0.616934   0.94374808 0.6818203 ]\n",
      " [0.3595079  0.43703195 0.6976312  0.06022547]\n",
      " [0.66676672 0.67063787 0.21038256 0.1289263 ]]\n",
      "\n",
      "After Linear Transformation:\n",
      "\n",
      "Query Q:\n",
      " [[1.51247626 1.09863089 1.39448841 1.0737781 ]\n",
      " [1.98339872 3.1429815  1.01724654 1.9578046 ]\n",
      " [2.50417562 2.67012164 1.90311168 2.0526804 ]]\n",
      "\n",
      "Key K:\n",
      " [[0.13849282 1.47254087 0.92151004 1.81468107]\n",
      " [3.00093333 2.42764101 1.45206995 3.10952573]\n",
      " [1.63895949 2.68636137 1.64754501 3.36944393]]\n",
      "\n",
      "Value V:\n",
      " [[0.81565823 1.0054659  0.716421   0.67786097]\n",
      " [2.55772488 2.57514373 2.30826128 1.62149319]\n",
      " [2.09452067 2.29303777 1.87055164 1.48860757]]\n"
     ]
    }
   ],
   "source": [
    "# Random weight matrices for Q, K, V (4x4)\n",
    "np.random.seed(0)  # for consistent output\n",
    "W_q = np.random.rand(4, 4)\n",
    "W_k = np.random.rand(4, 4)\n",
    "W_v = np.random.rand(4, 4)\n",
    "\n",
    "print(\"Before Linear Transformation:\")\n",
    "print(\"\\nWeight matrix W_q:\\n\", W_q)\n",
    "print(\"\\nWeight matrix W_k:\\n\", W_k)\n",
    "print(\"\\nWeight matrix W_v:\\n\", W_v)\n",
    "\n",
    "# Linear transformations\n",
    "Q = X @ W_q\n",
    "K = X @ W_k\n",
    "V = X @ W_v\n",
    "\n",
    "print(\"\\nAfter Linear Transformation:\")\n",
    "print(\"\\nQuery Q:\\n\", Q)\n",
    "print(\"\\nKey K:\\n\", K)\n",
    "print(\"\\nValue V:\\n\", V)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Compute attention scores (Q·Kᵀ / √dk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Raw attention scores (Q·Kᵀ / sqrt(dk)):\n",
      " [[ 2.53042292  6.28487859  5.67286222]\n",
      " [ 4.69652452 10.57351751  9.98328327]\n",
      " [ 4.87868518 11.57163735 10.66450385]]\n"
     ]
    }
   ],
   "source": [
    "dk = Q.shape[1]  # 4\n",
    "scores = Q @ K.T / np.sqrt(dk)\n",
    "print(\"\\nRaw attention scores (Q·Kᵀ / sqrt(dk)):\\n\", scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Apply Softmax to get weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Attention Weights (after softmax):\n",
      " [[0.01495411 0.63870437 0.34634152]\n",
      " [0.00180039 0.64226049 0.35593913]\n",
      " [0.00088234 0.71178464 0.28733302]]\n"
     ]
    }
   ],
   "source": [
    "attention_weights = softmax(scores)\n",
    "print(\"\\nAttention Weights (after softmax):\\n\", attention_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Multiply by V to get final output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Output (weighted sum of V):\n",
      " [[2.37124698 2.45396559 2.13285971 1.56135821]\n",
      " [2.38971598 2.47190516 2.14959736 1.5724951 ]\n",
      " [2.42309392 2.49270038 2.1810883  1.58247816]]\n"
     ]
    }
   ],
   "source": [
    "output = attention_weights @ V\n",
    "print(\"\\nFinal Output (weighted sum of V):\\n\", output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
